{"cells":[{"cell_type":"markdown","metadata":{"id":"UKPBMMnFGzB8"},"source":["# Setting environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24121,"status":"ok","timestamp":1681178172099,"user":{"displayName":"Linji Wang","userId":"11084623136410812061"},"user_tz":240},"id":"5R2oERymFw69","outputId":"34b10dd7-639e-4c1d-9572-0a591cbb5cc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118164,"status":"ok","timestamp":1681178290261,"user":{"displayName":"Linji Wang","userId":"11084623136410812061"},"user_tz":240},"id":"3HHB6h--IMa5","outputId":"ee7b8d1f-841a-4368-80b1-5b0a2e2e52e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n","Collecting torch==1.12.1+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp39-cp39-linux_x86_64.whl (1837.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m945.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.13.1+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp39-cp39-linux_x86_64.whl (23.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==0.12.1\n","  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp39-cp39-linux_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.12.1+cu113) (4.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu113) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu113) (8.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu113) (2.27.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu113) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu113) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu113) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu113) (1.26.15)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0+cu118\n","    Uninstalling torch-2.0.0+cu118:\n","      Successfully uninstalled torch-2.0.0+cu118\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.15.1+cu118\n","    Uninstalling torchvision-0.15.1+cu118:\n","      Successfully uninstalled torchvision-0.15.1+cu118\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.0.1+cu118\n","    Uninstalling torchaudio-2.0.1+cu118:\n","      Successfully uninstalled torchaudio-2.0.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.1+cu113 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.1+cu113 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.12.1+cu113 torchaudio-0.12.1+cu113 torchvision-0.13.1+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (8.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n","Collecting pyspng\n","  Downloading pyspng-0.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ninja\n","  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (2.25.1)\n","Collecting imageio-ffmpeg==0.4.3\n","  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests) (2.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pyspng) (1.22.4)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Installing collected packages: ninja, pyspng, imageio-ffmpeg\n","  Attempting uninstall: imageio-ffmpeg\n","    Found existing installation: imageio-ffmpeg 0.4.8\n","    Uninstalling imageio-ffmpeg-0.4.8:\n","      Successfully uninstalled imageio-ffmpeg-0.4.8\n","Successfully installed imageio-ffmpeg-0.4.3 ninja-1.11.1 pyspng-0.1.1\n"]}],"source":["!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n","!pip3 install click requests tqdm pyspng ninja matplotlib imageio imageio-ffmpeg==0.4.3"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1681178290262,"user":{"displayName":"Linji Wang","userId":"11084623136410812061"},"user_tz":240},"id":"2u-occUiXRYe","outputId":"4f858c99-6cb6-429e-9ee8-e1d15217a830"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/16726/Computer-vision-learning/proj5\n"]}],"source":["%cd /content/drive/MyDrive/16726/Computer-vision-learning/proj5"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8966,"status":"ok","timestamp":1681178299223,"user":{"displayName":"Linji Wang","userId":"11084623136410812061"},"user_tz":240},"id":"w5bOo64IUGdE","outputId":"fe59eec7-2b7e-4022-e818-dea3c151343d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.14.2-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting GitPython!=3.1.29,>=1.0.0\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.1)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=aa93c4588369a8562d6dc42ef54972fd77bf693f5622d24ec7491d661ec7e227\n","  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.19.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.14.2\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":7810,"status":"ok","timestamp":1681178307030,"user":{"displayName":"Linji Wang","userId":"11084623136410812061"},"user_tz":240},"id":"j9EqjHY7UKWC","outputId":"51fbf3e9-45de-4a58-f667-e4322f071a65"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}],"source":["import wandb\n","wandb.login() \n","# f28f905cf0d1b2c32ca1a1e437fb871c2b0e14c2"]},{"cell_type":"code","source":["# StyleGAN, Latent: z\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 100 --perc_wgt 1 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 0 --perc_wgt 1 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 100 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 100 --perc_wgt 1 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 0 --perc_wgt 1 --reg_wgt 0\n","!python main.py --model stylegan --mode project --latent  --l1_wgt 100 --perc_wgt 0 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4d3UIgvbJdG","executionInfo":{"status":"ok","timestamp":1681151595522,"user_tz":240,"elapsed":297130,"user":{"displayName":"Linji Wang","userId":"11084623136410812061"}},"outputId":"7dd649ca-58d7-4062-9636-d4f1b80b3fb8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["205\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinjiw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/16726/Computer-vision-learning/proj5/wandb/run-20230410_182820-x3wlpr66\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstylegan_project_z_Perc1.0_100.0_1e-06_2023-04-10-18-28-20\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/x3wlpr66\u001b[0m\n","Wrapper.init: latent=z, z_dim=512, resolution=64\n","model stylegan loaded\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.mean = torch.tensor(mean).view(-1, 1, 1)\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.std = torch.tensor(std).view(-1, 1, 1)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","ModuleList(\n","  (norm): Normalization()\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU()\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU()\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU()\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (loss_10): Identity()\n",")\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","z: 512\n","param.shape torch.Size([1, 512])\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/LBFGS.py:257: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n","  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n","iter count [250] loss 340.552032\n","iter count [500] loss 339.451294\n","iter count [750] loss 327.580902\n","iter count [1000] loss 316.802673\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss █▆▆▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss █▇▅▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▂▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss ▁▁▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▇▇▇▇██████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss █▇▅▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss 28.07526\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss 293.25354\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss 321.3288\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstylegan_project_z_Perc1.0_100.0_1e-06_2023-04-10-18-28-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/x3wlpr66\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 5 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230410_182820-x3wlpr66/logs\u001b[0m\n","205\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinjiw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/16726/Computer-vision-learning/proj5/wandb/run-20230410_182908-734a9mc7\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstylegan_project_z_Perc1.0_0.0_1e-06_2023-04-10-18-29-08\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/734a9mc7\u001b[0m\n","Wrapper.init: latent=z, z_dim=512, resolution=64\n","model stylegan loaded\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.mean = torch.tensor(mean).view(-1, 1, 1)\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.std = torch.tensor(std).view(-1, 1, 1)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","ModuleList(\n","  (norm): Normalization()\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU()\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU()\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU()\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (loss_10): Identity()\n",")\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","z: 512\n","param.shape torch.Size([1, 512])\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/LBFGS.py:257: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n","  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n","iter count [250] loss 425.383118\n","iter count [500] loss 408.327423\n","iter count [750] loss 415.805817\n","iter count [1000] loss 413.869202\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss █▅▅▅▃▄▄▃▃▃▃▃▃▄▁▂▂▂▂▁▁▂▁▂▁▁▂▁▂▁▂▂▁▂▁▁▁▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss ▁▁▁▂▃▃▃▄▄▄▄▄▄▄██████████████████████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss █▅▅▅▃▄▄▃▃▃▃▃▃▄▁▂▂▂▂▁▁▂▁▂▁▁▂▁▂▁▂▂▁▂▁▁▁▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss 400.4328\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss 400.4328\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstylegan_project_z_Perc1.0_0.0_1e-06_2023-04-10-18-29-08\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/734a9mc7\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 5 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230410_182908-734a9mc7/logs\u001b[0m\n","205\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinjiw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/16726/Computer-vision-learning/proj5/wandb/run-20230410_182959-v38cf93b\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstylegan_project_z_Perc0.0_100.0_1e-06_2023-04-10-18-29-59\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/v38cf93b\u001b[0m\n","Wrapper.init: latent=z, z_dim=512, resolution=64\n","model stylegan loaded\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.mean = torch.tensor(mean).view(-1, 1, 1)\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.std = torch.tensor(std).view(-1, 1, 1)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","ModuleList(\n","  (norm): Normalization()\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU()\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU()\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU()\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (loss_10): Identity()\n",")\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","z: 512\n","param.shape torch.Size([1, 512])\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/LBFGS.py:257: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n","  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n","iter count [250] loss 25.391516\n","iter count [500] loss 23.505312\n","iter count [750] loss 21.281332\n","iter count [1000] loss 20.820740\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss █▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss ▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss █▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss 21.00099\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss 2e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss 21.00101\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstylegan_project_z_Perc0.0_100.0_1e-06_2023-04-10-18-29-59\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/v38cf93b\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 5 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230410_182959-v38cf93b/logs\u001b[0m\n","205\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinjiw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/16726/Computer-vision-learning/proj5/wandb/run-20230410_183049-kzdrf417\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstylegan_project_z_Perc1.0_100.0_0.0_2023-04-10-18-30-49\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/kzdrf417\u001b[0m\n","Wrapper.init: latent=z, z_dim=512, resolution=64\n","model stylegan loaded\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.mean = torch.tensor(mean).view(-1, 1, 1)\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.std = torch.tensor(std).view(-1, 1, 1)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","ModuleList(\n","  (norm): Normalization()\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU()\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU()\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU()\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (loss_10): Identity()\n",")\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","z: 512\n","param.shape torch.Size([1, 512])\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/LBFGS.py:257: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n","  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n","iter count [250] loss 323.339050\n","iter count [500] loss 262.029633\n","iter count [750] loss 264.336029\n","iter count [1000] loss 257.892609\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss █▇▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss █▇▅▄▄▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss █▇▅▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss 23.76168\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss 238.10234\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss 261.86401\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstylegan_project_z_Perc1.0_100.0_0.0_2023-04-10-18-30-49\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/kzdrf417\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 5 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230410_183049-kzdrf417/logs\u001b[0m\n","205\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinjiw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/16726/Computer-vision-learning/proj5/wandb/run-20230410_183140-wrhlkwk8\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstylegan_project_z_Perc1.0_0.0_0.0_2023-04-10-18-31-40\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/wrhlkwk8\u001b[0m\n","Wrapper.init: latent=z, z_dim=512, resolution=64\n","model stylegan loaded\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.mean = torch.tensor(mean).view(-1, 1, 1)\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.std = torch.tensor(std).view(-1, 1, 1)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","ModuleList(\n","  (norm): Normalization()\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU()\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU()\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU()\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (loss_10): Identity()\n",")\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","z: 512\n","param.shape torch.Size([1, 512])\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/LBFGS.py:257: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n","  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n","iter count [250] loss 309.443268\n","iter count [500] loss 291.044525\n","iter count [750] loss 286.144165\n","iter count [1000] loss 271.346375\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss ██▇▇▇▆▄▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▂▂▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss ██▇▇▇▆▄▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▂▂▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss 275.05753\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss 275.05753\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstylegan_project_z_Perc1.0_0.0_0.0_2023-04-10-18-31-40\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/wrhlkwk8\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 5 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230410_183140-wrhlkwk8/logs\u001b[0m\n","205\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinjiw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/16726/Computer-vision-learning/proj5/wandb/run-20230410_183228-ocu4f23s\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstylegan_project_z_Perc0.0_100.0_0.0_2023-04-10-18-32-28\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/ocu4f23s\u001b[0m\n","Wrapper.init: latent=z, z_dim=512, resolution=64\n","model stylegan loaded\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.mean = torch.tensor(mean).view(-1, 1, 1)\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.std = torch.tensor(std).view(-1, 1, 1)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","ModuleList(\n","  (norm): Normalization()\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU()\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU()\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU()\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (loss_10): Identity()\n",")\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","z: 512\n","param.shape torch.Size([1, 512])\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/LBFGS.py:257: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n","  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n","iter count [250] loss 26.115059\n","iter count [500] loss 22.385490\n","iter count [750] loss 22.000086\n","iter count [1000] loss 21.921658\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss █▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss █▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss 21.93523\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss 21.93523\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstylegan_project_z_Perc0.0_100.0_0.0_2023-04-10-18-32-28\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/ocu4f23s\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 5 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230410_183228-ocu4f23s/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python main.py --model stylegan --mode interpolate --latent w+ --l1_wgt 50 --perc_wgt 1 --reg_wgt 1e-7 --n_iters 3000 --resolution 512 --input \"data/cute_cat/*.png\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibiUFm8DtJxV","executionInfo":{"status":"ok","timestamp":1681179661007,"user_tz":240,"elapsed":1353983,"user":{"displayName":"Linji Wang","userId":"11084623136410812061"}},"outputId":"a07969da-db19-4c7a-d4eb-5e286b2d1cfa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Wrapper.init: latent=w+, z_dim=512, resolution=512\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinjiw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/16726/Computer-vision-learning/proj5/wandb/run-20230411_015839-uib6lyqs\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstylegan_interpolate_w+_Perc1.0_50.0_1e-07_2023-04-11-01-58-38\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/uib6lyqs\u001b[0m\n","5\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.mean = torch.tensor(mean).view(-1, 1, 1)\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/main.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.std = torch.tensor(std).view(-1, 1, 1)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","100% 548M/548M [00:07<00:00, 73.9MB/s]\n","ModuleList(\n","  (norm): Normalization()\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU()\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU()\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU()\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (loss_10): Identity()\n",")\n","w+: 512\n","param.shape torch.Size([1, 10, 512])\n","/content/drive/MyDrive/16726/Computer-vision-learning/proj5/LBFGS.py:257: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n","  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n","iter count [250] loss 17.188833\n","iter count [500] loss 16.694033\n","iter count [750] loss 15.956462\n","iter count [1000] loss 15.818049\n","iter count [1250] loss 15.423988\n","iter count [1500] loss 14.893070\n","iter count [1750] loss 14.797235\n","iter count [2000] loss 14.724528\n","iter count [2250] loss 14.356920\n","iter count [2500] loss 14.392267\n","iter count [2750] loss 14.089685\n","iter count [3000] loss 13.995384\n","w+: 512\n","param.shape torch.Size([1, 10, 512])\n","iter count [250] loss 51.873428\n","iter count [500] loss 49.161114\n","iter count [750] loss 46.490818\n","iter count [1000] loss 45.225929\n","iter count [1250] loss 44.823761\n","iter count [1500] loss 44.301113\n","iter count [1750] loss 42.638527\n","iter count [2000] loss 41.640327\n","iter count [2250] loss 41.302395\n","iter count [2500] loss 41.096119\n","iter count [2750] loss 40.885426\n","iter count [3000] loss 39.986816\n","w+: 512\n","param.shape torch.Size([1, 10, 512])\n","iter count [250] loss 44.121292\n","iter count [500] loss 42.172840\n","iter count [750] loss 41.629917\n","iter count [1000] loss 41.076336\n","iter count [1250] loss 40.212536\n","iter count [1500] loss 40.107685\n","iter count [1750] loss 39.645123\n","iter count [2000] loss 39.503990\n","iter count [2250] loss 39.174725\n","iter count [2500] loss 38.548458\n","iter count [2750] loss 37.994953\n","iter count [3000] loss 37.986824\n","w+: 512\n","param.shape torch.Size([1, 10, 512])\n","iter count [250] loss 59.930557\n","iter count [500] loss 58.311516\n","iter count [750] loss 55.787155\n","iter count [1000] loss 54.700218\n","iter count [1250] loss 54.225147\n","iter count [1500] loss 53.363094\n","iter count [1750] loss 52.003696\n","iter count [2000] loss 51.377861\n","iter count [2250] loss 51.112072\n","iter count [2500] loss 50.530621\n","iter count [2750] loss 50.249779\n","iter count [3000] loss 49.935005\n","w+: 512\n","param.shape torch.Size([1, 10, 512])\n","iter count [250] loss 90.633324\n","iter count [500] loss 90.625320\n","iter count [750] loss 89.548050\n","iter count [1000] loss 89.014053\n","iter count [1250] loss 88.955826\n","iter count [1500] loss 86.800575\n","iter count [1750] loss 86.993797\n","iter count [2000] loss 85.462807\n","iter count [2250] loss 85.526695\n","iter count [2500] loss 83.921013\n","iter count [2750] loss 83.218307\n","iter count [3000] loss 82.086868\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss ▂▂▁▁▁▁▁▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▄▄▃▃▃▃▂▂▄▄▄▃▃▃▃▃\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss ▁▁▁▁▁▁▁▁▄▄▄▄▃▃▃▃▄▄▃▃▃▃▃▃▅▅▅▅▄▄▄▄███████▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss ▃▄▅▅▆▆▆▇▁▄▅▅▆▆▆▇▃▄▅▆▆▆▇▇▃▄▅▆▇▇██▂▂▂▂▂▃▄▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss ▁▁▁▁▁▁▁▁▅▄▄▄▄▄▃▃▄▄▄▃▃▃▃▃▅▅▅▅▄▄▄▄██████▇▇\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:         L1 Loss 6.08041\n","\u001b[34m\u001b[1mwandb\u001b[0m: Perceptual Loss 75.69827\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Reg Loss 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Total Loss 81.77869\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstylegan_interpolate_w+_Perc1.0_50.0_1e-07_2023-04-11-01-58-38\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/linjiw/hw5-GAN%20Photo%20Editing/runs/uib6lyqs\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 172 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230411_015839-uib6lyqs/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python main.py --model stylegan --mode interpolate --latent w+ --l1_wgt 100 --perc_wgt 1 --reg_wgt 1e-6 --n_iters 5000 --resolution 512\n"],"metadata":{"id":"B0Q-lQISi50B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# StyleGAN, Latent: w+\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 100 --perc_wgt 1 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 0 --perc_wgt 1 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 100 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 100 --perc_wgt 1 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 0 --perc_wgt 1 --reg_wgt 0\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 100 --perc_wgt 0 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n"],"metadata":{"id":"nQZN9InpYwc7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# StyleGAN, Latent: w\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 100 --perc_wgt 1 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 1 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 100 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 100 --perc_wgt 1 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 1 --reg_wgt 0\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 100 --perc_wgt 0 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n"],"metadata":{"id":"rv4OZhPWXup-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vanilla GAN, Latent: z\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 100 --perc_wgt 1 --reg_wgt 1e-6\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 0 --perc_wgt 1 --reg_wgt 1e-6\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 100 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 100 --perc_wgt 1 --reg_wgt 0\n","# !python main.py --model vanilla --mode project --latent z --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 0 --perc_wgt 1 --reg_wgt 0\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 100 --perc_wgt 0 --reg_wgt 0\n","# !python main.py --model vanilla --mode project --latent z --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n"],"metadata":{"id":"IHkOl8QlhmiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vanilla GAN, Latent: z\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 1e-6\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 1e-6\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 10 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 0\n","# !python main.py --model vanilla --mode project --latent z --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 0\n","!python main.py --model vanilla --mode project --latent z --l1_wgt 10 --perc_wgt 0 --reg_wgt 0\n","# !python main.py --model vanilla --mode project --latent z --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n","\n","# # Vanilla GAN, Latent: w\n","# !python main.py --model vanilla --mode project --latent w --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 1e-6\n","# !python main.py --model vanilla --mode project --latent w --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 1e-6\n","# !python main.py --model vanilla --mode project --latent w --l1_wgt 10 --perc_wgt 0 --reg_wgt 1e-6\n","# !python main.py --model vanilla --mode project --latent w --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 0\n","# # !python main.py --model vanilla --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","# !python main.py --model vanilla --mode project --latent w --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 0\n","# !python main.py --model vanilla --mode project --latent w --l1_wgt 10 --perc_wgt 0 --reg_wgt 0\n","# # !python main.py --model vanilla --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n","\n","# # Vanilla GAN, Latent: w+\n","# !python main.py --model vanilla --mode project --latent w+ --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 1e-6\n","# !python main.py --model vanilla --mode project --latent w+ --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 1e-6\n","# !python main.py --model vanilla --mode project --latent w+ --l1_wgt 10 --perc_wgt 0 --reg_wgt 1e-6\n","# !python main.py --model vanilla --mode project --latent w+ --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 0\n","# # !python main.py --model vanilla --mode project --latent w+ --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","# !python main.py --model vanilla --mode project --latent w+ --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 0\n","# !python main.py --model vanilla --mode project --latent w+ --l1_wgt 10 --perc_wgt 0 --reg_wgt 0\n","# # !python main.py --model vanilla --mode project --latent w+ --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n","\n","\n","# StyleGAN, Latent: z\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 10 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent z --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 0\n","!python main.py --model stylegan --mode project --latent z --l1_wgt 10 --perc_wgt 0 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent z --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n","\n","# StyleGAN, Latent: w\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 10 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 0\n","!python main.py --model stylegan --mode project --latent w --l1_wgt 10 --perc_wgt 0 --reg_wgt 0\n","# !python main.py --model stylegan --mode project --latent w --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n","\n","# StyleGAN, Latent: w+\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 10 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 0\n","# !python main.py --model vanilla --mode project --latent w+ --l1_wgt 0 --perc_wgt 0 --reg_wgt 1e-6\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 0 --perc_wgt 0.01 --reg_wgt 0\n","!python main.py --model stylegan --mode project --latent w+ --l1_wgt 10 --perc_wgt 0 --reg_wgt 0\n","# !python main.py --model vanilla --mode project --latent w+ --l1_wgt 0 --perc_wgt 0 --reg_wgt 0\n"],"metadata":{"id":"9OcscU0u6hhc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QyR4R_doWd7U"},"outputs":[],"source":["!python main.py --model vanilla --mode project --latent z --l1_wgt 10 --perc_wgt 0.01 --reg_wgt 1e-6 --resolution 512 --n_iters 10000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHVv4OJanUPG"},"outputs":[],"source":["!python main.py --model stylegan --mode project --latent w+ --input \"/content/cute.png\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5C5VKPtaf52f"},"outputs":[],"source":["!python main.py --model stylegan --mode project --latent w"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJ5IAcGIjl3k"},"outputs":[],"source":["!python main.py --model stylegan --mode project --latent w+ --regularization False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCfd6qonYhN6"},"outputs":[],"source":["!python main.py --model stylegan --mode project --latent w+ --regularization True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66JQRxGRnIM5"},"outputs":[],"source":["!python main.py --model stylegan --mode interpolate --latent w+ --regularization False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBPmCpI8Yx83"},"outputs":[],"source":["!python main.py --model stylegan --mode interpolate --latent z --regularization False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BI1qzdo7--5s"},"outputs":[],"source":["!python main.py --model stylegan --mode interpolate --latent w+ --n_iters 1500 --input \"data/cat/100.png\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vfXY65IboJzv"},"outputs":[],"source":["!python main.py --model stylegan --mode interpolate --latent w+ --n_iters 10000 --input \"/content/*.png\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6igJb1vY1RS"},"outputs":[],"source":["!python main.py --model stylegan --mode interpolate --latent w --regularization False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rYQYF9HkdAfX"},"outputs":[],"source":["!python main.py  --model stylegan --mode draw --resolution 64 --latent w+ --input \"data/cute_sketch/super_smile.png\" --regularization False --n_iters 10000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stZPrkoQgycD"},"outputs":[],"source":["!python main.py  --model stylegan --mode draw --latent w+ --input \"/content/*.png\" --regularization False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJ_-dWmThJ9g"},"outputs":[],"source":["!python main.py  --model stylegan --mode draw --input \"data/sketch/*.png\" --latent w+ --l1_wgt 10 --perc_wgt 1 --reg_wgt 1e-6 --n_iters 3000"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyP2AMo9PDPbtf5xxiooyj02"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}